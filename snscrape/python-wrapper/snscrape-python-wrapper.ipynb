{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article Notebook for Scraping Twitter Using snscrape's Python Wrapper\n",
    "<br>Package Github: https://github.com/JustAnotherArchivist/snscrape\n",
    "<br>This notebook will be using the development version of snscrape\n",
    "\n",
    "Article Read-Along: https://medium.com/better-programming/how-to-scrape-tweets-with-snscrape-90124ed006af\n",
    "\n",
    "### Notebook Author: Martin Beck\n",
    "<b>Information current as of November, 28th 2020</b><br>\n",
    "\n",
    "This notebook contains materials for scraping tweets from Twitter using snscrape's Python Wrapper\n",
    "\n",
    "<b>Dependencies: </b> \n",
    "- Your <b>Python</b> version must be <b>3.8</b> or higher. The development version of snscrape will not work with Python 3.7 or lower. You can download the latest Python version [here](https://www.python.org/downloads/).\n",
    "- <b>Development version of snscrape</b>, uncomment the pip install line in the below cell to pip install in the notebook if you don't already have it.\n",
    "- <b>Pandas</b>, the dataframes allows easy manipulation and indexing of data, this is more of a preference but is what I follow in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the pip install command below if you don't already have the library\n",
    "# !pip install git+https://github.com/JustAnotherArchivist/snscrape.git\n",
    "\n",
    "# Run the below command if you don't already have Pandas\n",
    "# !pip install pandas\n",
    "\n",
    "# Imports\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query by Username\n",
    "The code below will scrape for 100 tweets by a username then provide a CSV file with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting variables to be used below\n",
    "maxTweets = 100\n",
    "\n",
    "# Creating list to append tweet data to\n",
    "tweets_list1 = []\n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('from:jack').get_items()):\n",
    "    if i>maxTweets:\n",
    "        break\n",
    "    tweets_list1.append([tweet.date, tweet.id, tweet.content, tweet.user.username])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-27 21:25:36+00:00</td>\n",
       "      <td>1332435430801690624</td>\n",
       "      <td>@JesseDorogusker @Square ❤️</td>\n",
       "      <td>jack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-18 19:49:02+00:00</td>\n",
       "      <td>1329149637006041088</td>\n",
       "      <td>@NeerajKA Welcome!</td>\n",
       "      <td>jack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-18 18:59:50+00:00</td>\n",
       "      <td>1329137255026311168</td>\n",
       "      <td>Join @CashApp! #Bitcoin https://t.co/SbYANIZyix</td>\n",
       "      <td>jack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-18 18:57:29+00:00</td>\n",
       "      <td>1329136665684705280</td>\n",
       "      <td>@kateconger @sarahintampa Nah</td>\n",
       "      <td>jack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-18 18:54:05+00:00</td>\n",
       "      <td>1329135806192107521</td>\n",
       "      <td>@mmasnick Terrible idea! And terribly false.</td>\n",
       "      <td>jack</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datetime             Tweet Id  \\\n",
       "0 2020-11-27 21:25:36+00:00  1332435430801690624   \n",
       "1 2020-11-18 19:49:02+00:00  1329149637006041088   \n",
       "2 2020-11-18 18:59:50+00:00  1329137255026311168   \n",
       "3 2020-11-18 18:57:29+00:00  1329136665684705280   \n",
       "4 2020-11-18 18:54:05+00:00  1329135806192107521   \n",
       "\n",
       "                                              Text Username  \n",
       "0                      @JesseDorogusker @Square ❤️     jack  \n",
       "1                               @NeerajKA Welcome!     jack  \n",
       "2  Join @CashApp! #Bitcoin https://t.co/SbYANIZyix     jack  \n",
       "3                    @kateconger @sarahintampa Nah     jack  \n",
       "4     @mmasnick Terrible idea! And terribly false.     jack  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe from the tweets list above\n",
    "tweets_df1 = pd.DataFrame(tweets_list1, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])\n",
    "\n",
    "# Display first 5 entries from dataframe\n",
    "tweets_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataframe into a CSV\n",
    "tweets_df1.to_csv('user-tweets.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query by Text Search\n",
    "The code below will scrape for 500 tweets between June 1st, 2020 and July 31st, 2020, by a text search then provide a CSV file with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting variables to be used below\n",
    "maxTweets = 5000\n",
    "\n",
    "# Creating list to append tweet data to\n",
    "tweets_list2 = []\n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('xlhome since:2022-01-01 until:2022-01-30').get_items()):   \n",
    "    if i>maxTweets:\n",
    "        break\n",
    "    tweets_list2.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Username</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-29 12:57:57+00:00</td>\n",
       "      <td>1487409682327404546</td>\n",
       "      <td>ini xlhome ngedown lagi kah loading mulu pas b...</td>\n",
       "      <td>kkareomi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-28 16:36:51+00:00</td>\n",
       "      <td>1487102383427514369</td>\n",
       "      <td>@nawelshs i love xlhome</td>\n",
       "      <td>Atzer_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-28 11:03:22+00:00</td>\n",
       "      <td>1487018457803542528</td>\n",
       "      <td>@waguwagusuk ganti xlhome kakkkk, lancar jaya ...</td>\n",
       "      <td>yoshicat_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-28 06:41:23+00:00</td>\n",
       "      <td>1486952527882907648</td>\n",
       "      <td>@xlhomeid Duuh 4 hari internet mati tidak ada ...</td>\n",
       "      <td>FloraW44274560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-27 13:39:32+00:00</td>\n",
       "      <td>1486695368628731910</td>\n",
       "      <td>Sah! XL Axiata Akuisisi Link Net Senilai Rp 8,...</td>\n",
       "      <td>OniDewono</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datetime             Tweet Id  \\\n",
       "0 2022-01-29 12:57:57+00:00  1487409682327404546   \n",
       "1 2022-01-28 16:36:51+00:00  1487102383427514369   \n",
       "2 2022-01-28 11:03:22+00:00  1487018457803542528   \n",
       "3 2022-01-28 06:41:23+00:00  1486952527882907648   \n",
       "4 2022-01-27 13:39:32+00:00  1486695368628731910   \n",
       "\n",
       "                                            Username            Text  \n",
       "0  ini xlhome ngedown lagi kah loading mulu pas b...        kkareomi  \n",
       "1                            @nawelshs i love xlhome          Atzer_  \n",
       "2  @waguwagusuk ganti xlhome kakkkk, lancar jaya ...       yoshicat_  \n",
       "3  @xlhomeid Duuh 4 hari internet mati tidak ada ...  FloraW44274560  \n",
       "4  Sah! XL Axiata Akuisisi Link Net Senilai Rp 8,...       OniDewono  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe from the tweets list above\n",
    "tweets_df2 = pd.DataFrame(tweets_list2, columns=['Datetime', 'Tweet Id', 'Username', 'Text'])\n",
    "\n",
    "# Display first 5 entries from dataframe\n",
    "tweets_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataframe into a CSV\n",
    "tweets_df2.to_csv('text-query-tweets-v5.csv', sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
